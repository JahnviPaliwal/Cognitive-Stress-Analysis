{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO22gIyaGN5i",
        "outputId": "e561fba2-3e85-459c-b641-52bba8abf85f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading speechrecognition-3.14.3-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.14.0)\n",
            "Downloading speechrecognition-3.14.3-py3-none-any.whl (32.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJ9zIExbF19M",
        "outputId": "ac61c29b-fddc-4106-fba2-26cb10fc6da6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis Results:\n",
            "   cluster  anomaly_score  similarity_score\n",
            "0        0              1               0.0\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import speech_recognition as sr\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 1. Audio Preprocessing\n",
        "def audio_to_text(file_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio)\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "# 2. Feature Extraction Functions\n",
        "def extract_acoustic_features(audio_path):\n",
        "    y, sr = librosa.load(audio_path)\n",
        "\n",
        "    # Speech rate (syllables per second approximation)\n",
        "    duration = librosa.get_duration(y=y)\n",
        "    words = len(word_tokenize(audio_to_text(audio_path)))\n",
        "    speech_rate = words/(duration/60)  # Words per minute\n",
        "\n",
        "    # Pitch features\n",
        "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
        "    pitch_mean = np.mean(pitches[pitches > 0])\n",
        "    pitch_std = np.std(pitches[pitches > 0])\n",
        "\n",
        "    # Pause analysis\n",
        "    intervals = librosa.effects.split(y, top_db=20)\n",
        "    pause_durations = [librosa.samples_to_time(i[1]-i[0], sr=sr) for i in intervals]\n",
        "\n",
        "    return {\n",
        "        'speech_rate': speech_rate,\n",
        "        'pitch_mean': pitch_mean,\n",
        "        'pitch_std': pitch_std,\n",
        "        'avg_pause_duration': np.mean(pause_durations),\n",
        "        'pause_frequency': len(pause_durations)\n",
        "    }\n",
        "\n",
        "def linguistic_features(text):\n",
        "    hesitation_count = text.lower().count('uh') + text.lower().count('um')\n",
        "    words = word_tokenize(text)\n",
        "    word_count = len(words)\n",
        "\n",
        "    # Sentence complexity (simple metric)\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    avg_sentence_length = sum(len(s.split()) for s in sentences)/len(sentences) if sentences else 0\n",
        "\n",
        "    return {\n",
        "        'hesitation_count': hesitation_count,\n",
        "        'word_count': word_count,\n",
        "        'avg_sentence_length': avg_sentence_length,\n",
        "        'hesitation_ratio': hesitation_count/word_count if word_count else 0\n",
        "    }\n",
        "\n",
        "# 3. Data Processing Pipeline\n",
        "def process_audio_samples(file_paths):\n",
        "    features = []\n",
        "\n",
        "    for path in file_paths:\n",
        "        text = audio_to_text(path)\n",
        "        acoustic = extract_acoustic_features(path)\n",
        "        linguistic = linguistic_features(text)\n",
        "\n",
        "        combined_features = {**acoustic, **linguistic}\n",
        "        features.append(combined_features)\n",
        "\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "# 4. Machine Learning Models\n",
        "def apply_unsupervised_learning(df):\n",
        "    # Normalize features\n",
        "    df_normalized = (df - df.mean()) / df.std()\n",
        "\n",
        "    # Handle NaN values (replace with mean of the column)\n",
        "    df_normalized = df_normalized.fillna(0) # Replace NaN with the mean of each column\n",
        "\n",
        "    # Clustering\n",
        "    # Check if there are enough samples for clustering\n",
        "    if df_normalized.shape[0] >= 2:  # Check if there are at least 2 samples\n",
        "        kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "        df['cluster'] = kmeans.fit_predict(df_normalized)\n",
        "    else:\n",
        "        # If not enough samples, assign all to a single cluster or handle appropriately\n",
        "        df['cluster'] = 0  # Assign all to cluster 0, for example\n",
        "\n",
        "    # Anomaly Detection\n",
        "    iso_forest = IsolationForest(contamination=0.1)\n",
        "    df['anomaly_score'] = iso_forest.fit_predict(df_normalized)\n",
        "\n",
        "    # Similarity Scoring\n",
        "    reference = df_normalized.mean().values.reshape(1, -1)\n",
        "    df['similarity_score'] = cosine_similarity(df_normalized, reference)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 5. Usage Example\n",
        "if __name__ == \"__main__\":\n",
        "    # Simulated file paths (replace with actual paths)\n",
        "    audio_files = ['/content/drive/MyDrive/most stressful 10 minutes of my existence (10 minute song) [peG6ZC1M-Uw] (1)-[AudioTrimmer.com].wav']\n",
        "\n",
        "    # Process samples\n",
        "    feature_df = process_audio_samples(audio_files)\n",
        "\n",
        "    # Apply ML\n",
        "    results_df = apply_unsupervised_learning(feature_df)\n",
        "\n",
        "    # Display results\n",
        "    print(\"Analysis Results:\")\n",
        "    print(results_df[['cluster', 'anomaly_score', 'similarity_score']])\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_csv('cognitive_analysis_results.csv', index=False)\n"
      ]
    }
  ]
}
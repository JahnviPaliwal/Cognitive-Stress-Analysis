{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FO22gIyaGN5i",
        "outputId": "87e1278c-6397-469c-f11b-02740bdce355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.13.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "XJ9zIExbF19M",
        "outputId": "809043ce-26fd-4006-c7d6-f58bc8479d81"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'speech_recognition'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7b485ee75f85>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspeech_recognition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speech_recognition'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Import libraries\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import speech_recognition as sr\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# 1. Audio Preprocessing\n",
        "def audio_to_text(file_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio)\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "# 2. Feature Extraction Functions\n",
        "def extract_acoustic_features(audio_path):\n",
        "    y, sr = librosa.load(audio_path)\n",
        "\n",
        "    # Speech rate (syllables per second approximation)\n",
        "    duration = librosa.get_duration(y=y)\n",
        "    words = len(word_tokenize(audio_to_text(audio_path)))\n",
        "    speech_rate = words/(duration/60)  # Words per minute\n",
        "\n",
        "    # Pitch features\n",
        "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
        "    pitch_mean = np.mean(pitches[pitches > 0])\n",
        "    pitch_std = np.std(pitches[pitches > 0])\n",
        "\n",
        "    # Pause analysis\n",
        "    intervals = librosa.effects.split(y, top_db=20)\n",
        "    pause_durations = [librosa.samples_to_time(i[1]-i[0], sr=sr) for i in intervals]\n",
        "\n",
        "    return {\n",
        "        'speech_rate': speech_rate,\n",
        "        'pitch_mean': pitch_mean,\n",
        "        'pitch_std': pitch_std,\n",
        "        'avg_pause_duration': np.mean(pause_durations),\n",
        "        'pause_frequency': len(pause_durations)\n",
        "    }\n",
        "\n",
        "def linguistic_features(text):\n",
        "    hesitation_count = text.lower().count('uh') + text.lower().count('um')\n",
        "    words = word_tokenize(text)\n",
        "    word_count = len(words)\n",
        "\n",
        "    # Sentence complexity (simple metric)\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    avg_sentence_length = sum(len(s.split()) for s in sentences)/len(sentences) if sentences else 0\n",
        "\n",
        "    return {\n",
        "        'hesitation_count': hesitation_count,\n",
        "        'word_count': word_count,\n",
        "        'avg_sentence_length': avg_sentence_length,\n",
        "        'hesitation_ratio': hesitation_count/word_count if word_count else 0\n",
        "    }\n",
        "\n",
        "# 3. Data Processing Pipeline\n",
        "def process_audio_samples(file_paths):\n",
        "    features = []\n",
        "\n",
        "    for path in file_paths:\n",
        "        text = audio_to_text(path)\n",
        "        acoustic = extract_acoustic_features(path)\n",
        "        linguistic = linguistic_features(text)\n",
        "\n",
        "        combined_features = {**acoustic, **linguistic}\n",
        "        features.append(combined_features)\n",
        "\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "# 4. Machine Learning Models\n",
        "def apply_unsupervised_learning(df):\n",
        "    # Normalize features\n",
        "    df_normalized = (df - df.mean()) / df.std()\n",
        "\n",
        "    # Handle NaN values (replace with mean of the column)\n",
        "    df_normalized = df_normalized.fillna(0) # Replace NaN with the mean of each column\n",
        "\n",
        "    # Clustering\n",
        "    # Check if there are enough samples for clustering\n",
        "    if df_normalized.shape[0] >= 2:  # Check if there are at least 2 samples\n",
        "        kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "        df['cluster'] = kmeans.fit_predict(df_normalized)\n",
        "    else:\n",
        "        # If not enough samples, assign all to a single cluster or handle appropriately\n",
        "        df['cluster'] = 0  # Assign all to cluster 0, for example\n",
        "\n",
        "    # Anomaly Detection\n",
        "    iso_forest = IsolationForest(contamination=0.1)\n",
        "    df['anomaly_score'] = iso_forest.fit_predict(df_normalized)\n",
        "\n",
        "    # Similarity Scoring\n",
        "    reference = df_normalized.mean().values.reshape(1, -1)\n",
        "    df['similarity_score'] = cosine_similarity(df_normalized, reference)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 5. Usage Example\n",
        "if __name__ == \"__main__\":\n",
        "    # Simulated file paths (replace with actual paths)\n",
        "    audio_files = ['/content/drive/MyDrive/most stressful 10 minutes of my existence (10 minute song) [peG6ZC1M-Uw] (1)-[AudioTrimmer.com].wav']\n",
        "\n",
        "    # Process samples\n",
        "    feature_df = process_audio_samples(audio_files)\n",
        "\n",
        "    # Apply ML\n",
        "    results_df = apply_unsupervised_learning(feature_df)\n",
        "\n",
        "    # Display results\n",
        "    print(\"Analysis Results:\")\n",
        "    print(results_df[['cluster', 'anomaly_score', 'similarity_score']])\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_csv('cognitive_analysis_results.csv', index=False)\n"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing libraries\n"
      ],
      "metadata": {
        "id": "kbhJ8lk5aJ_z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import speech_recognition as sr\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt')\n",
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "id": "FO22gIyaGN5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing audio through drive/files"
      ],
      "metadata": {
        "id": "J0u2t5CXZv68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "2Sv57auOGKCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this cell to analyze audio and create a csv file"
      ],
      "metadata": {
        "id": "9nwWsV5iZix9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJ9zIExbF19M"
      },
      "outputs": [],
      "source": [
        "# 1. Audio Preprocessing\n",
        "def audio_to_text(file_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio)\n",
        "            return text\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "# 2. Feature Extraction Functions\n",
        "def extract_acoustic_features(audio_path):\n",
        "    y, sr = librosa.load(audio_path)\n",
        "\n",
        "    # Speech rate (syllables per second approximation)\n",
        "    duration = librosa.get_duration(y=y)\n",
        "    words = len(word_tokenize(audio_to_text(audio_path)))\n",
        "    speech_rate = words/(duration/60)  # Words per minute\n",
        "\n",
        "    # Pitch features\n",
        "    pitches, magnitudes = librosa.core.piptrack(y=y, sr=sr)\n",
        "    pitch_mean = np.mean(pitches[pitches > 0])\n",
        "    pitch_std = np.std(pitches[pitches > 0])\n",
        "\n",
        "    # Pause analysis\n",
        "    intervals = librosa.effects.split(y, top_db=20)\n",
        "    pause_durations = [librosa.samples_to_time(i[1]-i[0], sr=sr) for i in intervals]\n",
        "\n",
        "    return {\n",
        "        'speech_rate': speech_rate,\n",
        "        'pitch_mean': pitch_mean,\n",
        "        'pitch_std': pitch_std,\n",
        "        'avg_pause_duration': np.mean(pause_durations),\n",
        "        'pause_frequency': len(pause_durations)\n",
        "    }\n",
        "\n",
        "def linguistic_features(text):\n",
        "    hesitation_count = text.lower().count('uh') + text.lower().count('um')\n",
        "    words = word_tokenize(text)\n",
        "    word_count = len(words)\n",
        "\n",
        "    # Sentence complexity (simple metric)\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    avg_sentence_length = sum(len(s.split()) for s in sentences)/len(sentences) if sentences else 0\n",
        "\n",
        "    return {\n",
        "        'hesitation_count': hesitation_count,\n",
        "        'word_count': word_count,\n",
        "        'avg_sentence_length': avg_sentence_length,\n",
        "        'hesitation_ratio': hesitation_count/word_count if word_count else 0\n",
        "    }\n",
        "\n",
        "# 3. Data Processing Pipeline\n",
        "def process_audio_samples(file_paths):\n",
        "    features = []\n",
        "\n",
        "    for path in file_paths:\n",
        "        text = audio_to_text(path)\n",
        "        acoustic = extract_acoustic_features(path)\n",
        "        linguistic = linguistic_features(text)\n",
        "\n",
        "        combined_features = {**acoustic, **linguistic}\n",
        "        features.append(combined_features)\n",
        "\n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "# 4. Machine Learning Models\n",
        "def apply_unsupervised_learning(df):\n",
        "    # Normalize features\n",
        "    df_normalized = (df - df.mean()) / df.std()\n",
        "\n",
        "    # Handle NaN values (replace with mean of the column)\n",
        "    df_normalized = df_normalized.fillna(0) # Replace NaN with the mean of each column\n",
        "\n",
        "    # Clustering\n",
        "    # Check if there are enough samples for clustering\n",
        "    if df_normalized.shape[0] >= 2:  # Check if there are at least 2 samples\n",
        "        kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "        df['cluster'] = kmeans.fit_predict(df_normalized)\n",
        "    else:\n",
        "        # If not enough samples, assign all to a single cluster or handle appropriately\n",
        "        df['cluster'] = 0  # Assign all to cluster 0, for example\n",
        "\n",
        "    # Anomaly Detection\n",
        "    iso_forest = IsolationForest(contamination=0.1)\n",
        "    df['anomaly_score'] = iso_forest.fit_predict(df_normalized)\n",
        "\n",
        "    # Similarity Scoring\n",
        "    reference = df_normalized.mean().values.reshape(1, -1)\n",
        "    df['similarity_score'] = cosine_similarity(df_normalized, reference)\n",
        "\n",
        "    return df\n",
        "\n",
        "# 5. Usage Example\n",
        "if __name__ == \"__main__\":\n",
        "    # Simulated file paths (replace with actual paths)\n",
        "    audio_files = ['/content/drive/MyDrive/most stressful 10 minutes of my existence (10 minute song) [peG6ZC1M-Uw] (1)-[AudioTrimmer.com].wav']\n",
        "\n",
        "    # Process samples\n",
        "    feature_df = process_audio_samples(audio_files)\n",
        "\n",
        "    # Apply ML\n",
        "    results_df = apply_unsupervised_learning(feature_df)\n",
        "\n",
        "    # Display results\n",
        "    print(\"Analysis Results:\")\n",
        "    print(results_df[['cluster', 'anomaly_score', 'similarity_score']])\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_csv('cognitive_analysis_results.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emotion and speech recognition mathematical measures\n",
        "\n"
      ],
      "metadata": {
        "id": "SVepuK2uMRm3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix(row):\n",
        "  result = []\n",
        "\n",
        "#for speech rate 69,90,120,150-180\n",
        "\n",
        "  if float(row[0])<=135:    # Stressed\n",
        "    result.append('S')\n",
        "  elif float(row[0])<=149:    #Little bit stressed\n",
        "    result.append('N')\n",
        "  elif float(row[0])>=150:    #Normal\n",
        "    result.append('N')\n",
        "\n",
        "  else:\n",
        "    result.append('0')\n",
        "\n",
        "\n",
        "  result.extend([0,0])\n",
        "\n",
        "#for pitch mean\n",
        "\n",
        "  if float(row[3])<=0.5:         #Normal\n",
        "    result.append('N')\n",
        "  elif float(row[3])>0.5:     #stressfull\n",
        "    result.append('S')\n",
        "  else:\n",
        "    result.append('0')\n",
        "\n",
        "\n",
        "    #for pitch mean\n",
        "\n",
        "  if float(row[4])<=7:         #Normal\n",
        "    result.append('N')\n",
        "  elif float(row[4])>=8:     #stressfull\n",
        "    result.append('S')\n",
        "  else:\n",
        "    result.append('0')\n",
        "\n",
        "\n",
        "    #for Hesitation count\n",
        "\n",
        "  if float(row[5])<=2.5:         #Normal\n",
        "    result.append('N')\n",
        "  elif float(row[5])>2.5:     #stressfull\n",
        "    result.append('S')\n",
        "  else:\n",
        "    result.append('0')\n",
        "\n",
        "\n",
        "  # result[6]='0'\n",
        "  # result[7]='0'\n",
        "  # result[8]='0'\n",
        "  # result[9]='0'\n",
        "  # result[10]='0'\n",
        "  # result[11]='0'\n",
        "  # result[12]='0'\n",
        "\n",
        "  # print(result)\n",
        "\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "YlPbqiFdMTK_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Last cell-run to view results"
      ],
      "metadata": {
        "id": "4VIAyYHAZGxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p = open(f'/content/cognitive_analysis_results.csv','r')\n",
        "\n",
        "row = csv.reader(p)\n",
        "countS=0\n",
        "countN=0\n",
        "\n",
        "x=['speech_rate', 'pitch_mean', 'pitch_std', 'avg_pause_duration', 'pause_frequency', 'hesitation_count', 'word_count', 'avg_sentence_length', 'hesitation_ratio', 'cluster', 'anomaly_score', 'similarity_score']\n",
        "print(x)\n",
        "for i in row:\n",
        "  if i != x:\n",
        "    num = i\n",
        "    print(num)\n",
        "\n",
        "\n",
        "rel= matrix(num)\n",
        "\n",
        "for k in rel:\n",
        "  if k == \"S\":\n",
        "    countS+=1\n",
        "  if k == 'N':\n",
        "    countN+=1\n",
        "\n",
        "if countS>countN:\n",
        "  print(\"Stressful\")\n",
        "if countS==countN:\n",
        "  print(\"a little bit Stressfull\")\n",
        "else:\n",
        "  print(\"Normal\")\n",
        "\n",
        "p.close()\n",
        ""
      ],
      "metadata": {
        "id": "7ncKONxUHCEH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}